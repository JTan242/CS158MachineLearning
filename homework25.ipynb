{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxebqYTaL7Op"
   },
   "source": [
    "**Homework 25**\n",
    "\n",
    "In this assignment your will train a RNN to predict characters of *Alice in Wonderland*, from strings of consecutive characters.\n",
    "\n",
    "We begin as usual with the imports you will need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vnuC9CayTbrH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rdl0ITr5oWMz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=('cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DcpEWAcsiWv"
   },
   "source": [
    "Run the following text block to read *Alice in Wonderland* from the web, store it in the variable `text`, convert to lower case and remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lETC1jDaQrKp"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from urllib.request import urlopen\n",
    "url='https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt'\n",
    "text = urlopen(url).read().decode('utf-8')\n",
    "text=text.lower()\n",
    "text=[c for c in text if (c not in string.punctuation) and (c!='\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68T7cjSLRMEb"
   },
   "source": [
    "Write a class `Tokenizer` with the following methods:\n",
    "\n",
    "\n",
    "*   `__init__`, a method that builds a dictionary `tokens` whose keys are the set of unique characters in some input `text`, and values are integers.\n",
    "*   `encode`, a method that takes in a corpus of text, converts each character according to the dictionary built by the __init__ method, and outputs a list of those integers.\n",
    "*   `decode`, a method that takes a single integer (a value from the dictionary), and returns the corresponding character key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jBaSjQNWTEsB"
   },
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "  def __init__(self,text):\n",
    "    unique_chars = sorted(set(text))\n",
    "    self.tokens = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "    self.index_to_char = {idx: char for char, idx in self.tokens.items()}\n",
    "  def encode(self,text):\n",
    "    return [self.tokens[c] for c in text]\n",
    "\n",
    "  def decode(self,n):\n",
    "    return self.index_to_char[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTBoQ2PaU9I6"
   },
   "source": [
    "Now, create an object called `tok` of your `Tokenizer` class, and use it to encode `text` as a list of integers, `text_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lJnStdvpVEyw"
   },
   "outputs": [],
   "source": [
    "tok=Tokenizer(text)\n",
    "text_indices=tok.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMJOidgupSAY"
   },
   "source": [
    "For convenience, we'll define `vocab_size=len(tok.tokens)` to be the length of your tokenizer dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t9rHu8C_pYFf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(tok.tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0F-VTPcsvCY"
   },
   "source": [
    "The next task is to create feature sequences and targets. From `text_indices`, create a list-of-lists `X`. Each sublist of `X` should correspond to 50 consecutive elements of `text_indices`. At the same time, create a list `y` which contains the indices of the characters that follow each sublist of `X`. For example, `X[0]` should be a list containing the first 50 elements of `text_indices`: `text_indices[0]` through `text_indices[49]`. `y[0]` should be the 51st element, `text_indices[50]`.\n",
    "\n",
    "To keep the size of the feature and target vectors manageable, consecutive lists in `X` should be shifted by 3, so the overlap is 47 elements. Hence, `X[1]` should be a list containing the integers `text_indices[3]` through `text_indices[52]`, and `y[1]` should be the integer `text_indices[53]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VJ3XPYLUTjbA"
   },
   "outputs": [],
   "source": [
    "seq_len=50\n",
    "X=[]\n",
    "y=[]\n",
    "for i in range(0,len(text_indices)-seq_len-1,3):\n",
    "  X.append(text_indices[i:i+seq_len])\n",
    "  y.append(text_indices[i+seq_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5HcBpY_ut5T"
   },
   "source": [
    "Convert `X` and `y` to torch tensors with the same names, and check their shapes. If done correctly, the shape of `X` should be (45539, 50) and the shape of `y` should be (45539, ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tc1lvY5wUE_o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45539, 50]), torch.Size([45539]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor(X, dtype=torch.long, device=device)\n",
    "y=torch.tensor(y, dtype=torch.long, device=device)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYxo9IEjvLyR"
   },
   "source": [
    "Convert `X` to a one-hot encoded vector `OneHotX` of 0's and 1's, and check its shape. You should now have shape (45539,50,29). In other words, the vector `OneHotX` now contains 45,539 sequences of length 50, and each element of each sequence is a 29-dimensional vector of 28 zeros and a single one in the entry corresponding to some character in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GAkeXEhM0MOG"
   },
   "outputs": [],
   "source": [
    "OneHotX=F.one_hot(X, num_classes=vocab_size).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9aYcAmwwncs"
   },
   "source": [
    "You're now ready to create your model, which will consist of two seperate one-layer pytorch models. The first will be a recurrent layer that takes in sequences of 29-dimensional vectors, and has a 128 dimensional hidden state. The second will ve a linear layer that will take the last hidden state and produce a 29 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b0RbPYB0UmBp"
   },
   "outputs": [],
   "source": [
    "rnn=nn.RNN(\n",
    "    input_size=vocab_size,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    batch_first=True\n",
    ").to(device)\n",
    "\n",
    "fc=nn.Linear(128, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iqIfJNyx1xL"
   },
   "source": [
    "Compile your model using the `Adam` optimizer and an approporiately chosen loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XfvSeb5cU8nj"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(rnn.parameters()) + list(fc.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GIl_LiFx-zD"
   },
   "source": [
    "Fit your data to X and y. Train for 50 epochs with a batch size of 128. Each epoch will take about 95 seconds, so you'll want to leave your computer for about an hour for this to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9HMXgjxKVJb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, avg_loss: 2.3569527830032886\n",
      "epoch: 2, avg_loss: 1.970838583485066\n",
      "epoch: 4, avg_loss: 1.8402020468584421\n",
      "epoch: 6, avg_loss: 1.7479895551087563\n",
      "epoch: 8, avg_loss: 1.672956361211271\n",
      "epoch: 10, avg_loss: 1.6143653076935167\n",
      "epoch: 12, avg_loss: 1.562607200791937\n",
      "epoch: 14, avg_loss: 1.519829806960245\n",
      "epoch: 16, avg_loss: 1.4804779005321858\n",
      "epoch: 18, avg_loss: 1.4482061491069327\n",
      "epoch: 20, avg_loss: 1.4218611226659532\n",
      "epoch: 22, avg_loss: 1.3982054838071099\n",
      "epoch: 24, avg_loss: 1.3776010191930885\n",
      "epoch: 26, avg_loss: 1.357822932085843\n",
      "epoch: 28, avg_loss: 1.3397361304952173\n",
      "epoch: 30, avg_loss: 1.326487443211464\n",
      "epoch: 32, avg_loss: 1.3126609781890544\n",
      "epoch: 34, avg_loss: 1.3007591439972999\n",
      "epoch: 36, avg_loss: 1.2901715037353572\n",
      "epoch: 38, avg_loss: 1.2832508652590175\n",
      "epoch: 40, avg_loss: 1.2734292800431877\n",
      "epoch: 42, avg_loss: 1.2684789102966836\n",
      "epoch: 44, avg_loss: 1.2618339186707996\n",
      "epoch: 46, avg_loss: 1.2522757587237263\n",
      "epoch: 48, avg_loss: 1.2489957055329528\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "N = OneHotX.shape[0]  # total number of observations in training data\n",
    "batch_size=32\n",
    "\n",
    "rnn.train()\n",
    "for epoch in range(n_epochs):\n",
    "  epoch_loss = 0.0\n",
    "\n",
    "  # Shuffle the indices\n",
    "  indices = torch.randperm(N,device=device)\n",
    "\n",
    "  # Create mini-batches\n",
    "  for i in range(0, N, batch_size):\n",
    "    batch_indices = indices[i:i+batch_size]\n",
    "    batch_X = OneHotX[batch_indices]\n",
    "    batch_y = y[batch_indices]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output, hidden = rnn(batch_X)\n",
    "    output_last = output[:, -1, :]  \n",
    "    preds = fc(output_last)\n",
    "    loss = criterion(preds, batch_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()*batch_size\n",
    "\n",
    "  if epoch%2==0:\n",
    "      avg_loss = epoch_loss / len(y)\n",
    "      print(f\"epoch: {epoch}, avg_loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQcsGH5Jyb7e"
   },
   "source": [
    "We will now use your trained model to generate text, one character at a time. Run the following code block to do this. (It will take a minute or two to complete.) Its interesting that although the model generates one character at a time, you'll see very word-like strings in the final text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t4IrfYOGaVHn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ce repeate you oven up any own up to the rebbytis whet  here be reppoke befourlyly what have you begonbetuly as she had when they withta lome beapsinut with extrrildsail wore here getanding to put a fercapien and the picksuchange sore talkyor quetave  bytare wore and mound all the house cerdunting atoherell the ashe plane would her sone said the corsone  said aliceand the queen to tring were for no  algat and somesed and undance ashortlialf down  the pook  of asimf reser about it are hus hime ar'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.eval()\n",
    "next_seq=OneHotX[:1]  #Initial \"seed\" sequence\n",
    "\n",
    "newtext=''\n",
    "with torch.no_grad():\n",
    "  for i in range(500):\n",
    "    seq=next_seq\n",
    "    pred=fc(rnn(seq)[1].squeeze()) #predictions of your model\n",
    "    pred_probs=torch.softmax(pred,dim=0).detach().cpu().numpy() #predictions->probs\n",
    "    index_pred=np.random.choice(vocab_size,1,p=pred_probs)[0] #choose one\n",
    "    newtext+=tok.decode(index_pred) #corresponding character\n",
    "\n",
    "    next_vec=torch.zeros(vocab_size).to(device)\n",
    "    next_vec[index_pred]=1  #one-hot encode chosen letter index\n",
    "    next_seq=torch.zeros(1,seq_len,29).to(device)\n",
    "    next_seq[0,:seq_len-1]=seq[0,1:] #new sequence is last 49 of old sequence\n",
    "    next_seq[0,seq_len-1]=next_vec  #plus new vector\n",
    "\n",
    "newtext #display generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ce repeate you oven up any own up to the rebbytis whet  here be reppoke befourlyly what have you begonbetuly as she had when they withta lome beapsinut with extrrildsail wore here getanding to put a fercapien and the picksuchange sore talkyor quetave  bytare wore and mound all the house cerdunting atoherell the ashe plane would her sone said the corsone  said aliceand the queen to tring were for no  algat and somesed and undance ashortlialf down  the pook  of asimf reser about it are hus hime ar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk9dRoo_0Ok_"
   },
   "source": [
    "**COPY AND PASTE THIS TEXT INTO THE SUBMISSION WINDOW ON GRADESCOPE**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPjYw8hbnS58Zcpf44DCUpy",
   "provenance": [
    {
     "file_id": "1a7fdaeftlTzb6zEdH-idQ13R4Jm2_h8K",
     "timestamp": 1650312231146
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
